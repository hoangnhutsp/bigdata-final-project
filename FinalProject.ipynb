{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89b6fd0",
   "metadata": {},
   "source": [
    "# Đồ án cuối kỳ Big Data\n",
    "\n",
    "## Video Stream Analytics: Detect Object and Mask\n",
    "\n",
    "### Môn học \n",
    "- Công nghệ Dữ liệu lớn - IE212.M11\n",
    "- GV: Đỗ Trọng Hợp\n",
    "\n",
    "### Nhóm sinh viên thực hiện\n",
    "- Trang Hoàng Nhựt (18520123)\n",
    "- Nguyễn Ngọc Quí (18520410)\n",
    "- Nguyễn Thị Phương (18520135)\n",
    "- Lê Thị Minh Hiền (18520049)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb867d30",
   "metadata": {},
   "source": [
    "## 1. Khởi tạo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2ef1a",
   "metadata": {},
   "source": [
    "### 1.1 Khai báo thư viện sử dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5b50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "\n",
    "# Xử lý ảnh\n",
    "import numpy as np\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc586b",
   "metadata": {},
   "source": [
    "### 1.2 Khai báo đường dẫn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77a9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGIN_PATH = \"D:/uit/IE212 - Bigdata/final-project\"\n",
    "\n",
    "INPUT = ORIGIN_PATH + \"/streaming/input\"\n",
    "OUTPUT = ORIGIN_PATH + \"/streaming/output\"\n",
    "\n",
    "OBJECT_DETECTOR = ORIGIN_PATH + \"/model/object-detector\"\n",
    "FACE_MASK_DETECTOR = ORIGIN_PATH + \"/model/face-mask-detector\"\n",
    "\n",
    "SERVING = ORIGIN_PATH + '/serving'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c2c42",
   "metadata": {},
   "source": [
    "### 1.3 Khởi tạo spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7d34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"BIG DATA - Video Stream Analytics\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68929b80",
   "metadata": {},
   "source": [
    "### 1.4 Khai báo một số hàm dùng chung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00c9b7",
   "metadata": {},
   "source": [
    "Chuyển đổi định dạng file ảnh tương ứng:\n",
    "- **byte**: lưu trữ spark\n",
    "- **numpy array**: sử dụng cho các model\n",
    "- **base64**: dữ liệu raw từ spark streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb0a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_byte_to_nparr(img_byte):\n",
    "    np_array = cv2.imdecode(np.asarray(bytearray(img_byte)), cv2.IMREAD_COLOR)\n",
    "    return np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc2d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nparr_to_byte(img_np_array):\n",
    "    success, img = cv2.imencode('.png', img_np_array)\n",
    "    return img.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef8f80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_base64_to_nparr(raw_base64):\n",
    "    im_bytes = base64.b64decode(raw_base64)\n",
    "    im_arr = np.frombuffer(im_bytes, dtype=np.uint8)\n",
    "    return cv2.imdecode(im_arr, flags=cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f6cdf7",
   "metadata": {},
   "source": [
    "Lưu hình ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f25ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(path, file_name, image):\n",
    "    cv2.imwrite(path + \"/\" + file_name, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab73b97",
   "metadata": {},
   "source": [
    "Chuẩn hóa ***box(startX, startY, endX, endY)*** với hình ảnh có kích thước **(image_h, image_w)** tương với với hình ảnh có kích thước **(net_h, net_w)** (ảnh gốc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6d6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_boxes(startX, startY, endX, endY, image_h, image_w, net_h, net_w):\n",
    "    startX = startX * net_h / image_h\n",
    "    startY = startY * net_h / image_h\n",
    "    endX = endX * net_w / image_w\n",
    "    endY = endY * net_w / image_w\n",
    "    return int(startX), int(startY), int(endX), int(endY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf482296",
   "metadata": {},
   "source": [
    "Vẽ box với label tương ứng vào hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64239de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(image, startX, startY, endX, endY, label):\n",
    "    image = cv2.rectangle(image, (startX, startY), (endX, endY), (36,255,1))\n",
    "    cv2.putText(image, label, (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219f9f4",
   "metadata": {},
   "source": [
    "## 2. Class Object Detector\n",
    "Input:\n",
    "- **weights_path**: đường dẫn chứa file yolov3.weights\n",
    "- **configuration_path**: dường dẫn chứa file yolov3.cfg\n",
    "- **labels**: tương ứng với mô hình yolov3\n",
    "\n",
    "Mô hình sử dụng 2 thông số mặc định là **probability minimum = 0.5 và thresold = 0.3**.\n",
    "\n",
    "Mô hình *YOLO - You Only Look Once (v3)* là một trong những mô hình phát hiện vật thể tốt nhất. Mô hình phát hiện được 80 vật thể: person, bicycle, car, motorbike, aeroplane, bus, train,... Chi tiết xem tại file: *./model/object-detector/coco.names*.\n",
    "\n",
    "Mô hình YOLO sau khi lượt bỏ các đối tượng có độ chính xác thấp hơn **probability** (0.5), vẫn có khả năng sẽ phát hiện trùng lặp xung quanh một đối tượng. Vì thế, ta cần phải sử dụng **Non-Maximum Suppression (NMS)**, còn gọi là **Non-Maxima Suppression** để loại bỏ đi các đối tượng bị trùng lặp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ffe267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load danh sách label của mô hình YOLO từ file coco.names\n",
    "labels = open(OBJECT_DETECTOR + '/coco.names').read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "222fd325",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object_Detector():\n",
    "    \"\"\"Object Detector \n",
    "  \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 weights_path = 'yolov3.weights',\n",
    "                 configuration_path = 'file yolov3.cfg',\n",
    "                 labels = []):\n",
    "        \n",
    "        self.weights_path = weights_path\n",
    "        self.configuration_path = configuration_path\n",
    "        \n",
    "        self.probability_minimum = 0.5\n",
    "        self.threshold = 0.3\n",
    "        \n",
    "        self.labels = labels\n",
    "        \n",
    "        # Load mạng network của model YOLO\n",
    "        network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\n",
    "        layers_names_all = network.getLayerNames()\n",
    "        layers_names_output = [layers_names_all[i - 1] for i in network.getUnconnectedOutLayers()]\n",
    "        self.network = network\n",
    "        self.layers_names_output = layers_names_output\n",
    "        \n",
    "        # Non-Maximum Suppression (NMS) \n",
    "        self.NMSBoxes = cv2.dnn.NMSBoxes\n",
    "    def solve(self, image):\n",
    "        \"\"\"solve\n",
    "            input: image (numpy array)\n",
    "            output: Danh sách các đối tượng phát hiện tương ứng \n",
    "                [(startX, startY, endX, endY, label, confidences, obj_byte)]\n",
    "        \"\"\"\n",
    "        input_shape = image.shape\n",
    "        h, w = input_shape[:2]\n",
    "        \n",
    "        # Chuẩn hóa lại hình ảnh sử dụng model YOLO\n",
    "        blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    \n",
    "        self.network.setInput(blob)\n",
    "   \n",
    "        output_from_network = self.network.forward(self.layers_names_output)\n",
    "        \n",
    "        bounding_boxes = []\n",
    "        confidences = []\n",
    "        class_numbers = []\n",
    "    \n",
    "        for result in output_from_network:\n",
    "            for detection in result:\n",
    "                # Lấy danh sách các scores tương ứng với kết quả và tìm ra class với score lớn nhất\n",
    "                scores = detection[5:]\n",
    "                class_current = np.argmax(scores)\n",
    "                confidence_current = scores[class_current]\n",
    "                \n",
    "                # probability_minimum: 0.5\n",
    "                if confidence_current > self.probability_minimum:\n",
    "                    # Tính toán các giá trị: x_min, y_min, box_width, box_height, confidences, class_numbers\n",
    "                    # sử dụng cho Non-Maximum Suppression\n",
    "                    box_current = detection[0:4] * np.array([w, h, w, h])\n",
    "                    x_center, y_center, box_width, box_height = box_current.astype('int')\n",
    "                    x_min = int(x_center - (box_width / 2))\n",
    "                    y_min = int(y_center - (box_height / 2))\n",
    "                    bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "                    confidences.append(float(confidence_current))\n",
    "                    class_numbers.append(class_current)\n",
    "                    \n",
    "        # Kiểm tra nếu không tồn tại đối tượng trả về []\n",
    "        if len(bounding_boxes) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Tiến hành chuẩn hóa lại Boxes bằng cách sử dụng Non-Maximum Suppression\n",
    "        results = self.NMSBoxes(bounding_boxes, confidences, self.probability_minimum, self.threshold)\n",
    "        \n",
    "        obj_detection = []\n",
    "        for i in results.flatten():\n",
    "            # Đối với đối tượng phát hiện được ta tiến hành tính toán các giá trị:\n",
    "            # startX, startY, endX, endY, label, confidence, obj_byte\n",
    "            \n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "            startX = x_min\n",
    "            startY = y_min\n",
    "            endX = x_min + box_width\n",
    "            endY = y_min + box_height\n",
    "\n",
    "            (startX, startY) = (max(0, startX), max(0, startY))\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "            \n",
    "            obj_image = image[startY:endY, startX:endX]\n",
    "            obj_byte = convert_nparr_to_byte(obj_image)\n",
    "            \n",
    "            obj_detection.append((startX, startY, endX, endY, labels[int(class_numbers[i])], confidences[i], obj_byte))\n",
    "        return obj_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc72b3",
   "metadata": {},
   "source": [
    "## 3. Class Face Mask Detector\n",
    "Input:\n",
    "- **prototxtPath**: đường dẫn chứa file deploy.prototxt (Caffe model)\n",
    "- **weightsPath**: dường dẫn chứa file res10_300x300_ssd_iter_140000.caffemodel (Caffe model)\n",
    "- **mask_model_path**: Đường dẫn chứa file masknet_vgg19.h5\n",
    "\n",
    "Đối với mô hình Caffe, nhóm sử dụng thông số mặc định: **probability minimum = 0.5**.\n",
    "\n",
    "Sử dụng pretrain *model VGG19* của keras để train cho mô hình phát hiện khẩu trang có **accurency: 98.3%** đối với bộ dữ liệu  [Face Mask Detection ~12K Images Dataset](https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "612f3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face_Mask_Detector():\n",
    "    \"\"\"Face Mask Detector\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 prototxtPath = \"deploy.prototxt\",\n",
    "                 weightsPath = \"res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "                 mask_model_path = \"masknet_vgg19.h5\"):\n",
    "\n",
    "        self.net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "        self.vgg19_model = load_model(mask_model_path)\n",
    "        self.probability_minimum = 0.5\n",
    "\n",
    "\n",
    "    def face_mask_detection(self, face):\n",
    "        \"\"\"face_mask_detection: Kiểm tra xem khuôn mặt có đeo khẩu trang hay không\n",
    "            input: face (numpy array)\n",
    "            output: with_mask hoặc without_mask và confidence tương tứng. \n",
    "        \"\"\"\n",
    "        face = cv2.resize(face, (128, 128))\n",
    "        face = face / 255.0\n",
    "\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "        \n",
    "        # model tính toán và trả về tỉ lệ tương ứng    \n",
    "        (mask, withoutMask) = self.vgg19_model.predict(face)[0]\n",
    "        \n",
    "        label = 'with_mask'\n",
    "        confidence = mask\n",
    "        if mask < withoutMask:\n",
    "            label = 'without_mask'\n",
    "            confidence = withoutMask\n",
    "            \n",
    "        return label, confidence\n",
    "    def solve(self, x_origin, y_origin, image):\n",
    "        \"\"\"solve\n",
    "            input: image (numpy array)\n",
    "            output: Danh sách các đối tượng phát hiện tương ứng \n",
    "                [(startX, startY, endX, endY, label, confidences, obj_byte)]\n",
    "        \"\"\"\n",
    "        (net_h, net_w) = image.shape[:2]\n",
    "        (h, w) = image.shape[:2]\n",
    "        \n",
    "        # Chuẩn hóa lại hình ảnh sử dụng model Caffe\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        self.net.setInput(blob)\n",
    "        detections = self.net.forward()\n",
    "\n",
    "        extracted_face_list = []\n",
    "        \n",
    "        # Xử lý với từng khuôn mặt phát hiện\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            # probability_minimum: 0.5\n",
    "            if confidence > self.probability_minimum:\n",
    "                # Tính toán các giá trị: startX, startY, endX, endY, label, confidence, obj_byte\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                (startX, startY) = (max(0, startX), max(0, startY))\n",
    "                (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "                \n",
    "                # Tính toán lại các trị startX, startY, endX, endY tương ứng với kích thước ảnh gốc\n",
    "                startX, startY, endX, endY = correct_boxes(startX, startY, endX, endY, h, w, net_h, net_w)\n",
    "                \n",
    "                # Kiểm tra xem khuôn mặt có đeo khẩu trang hay không\n",
    "                face = image[startY:endY, startX:endX]\n",
    "                label, confidence = self.face_mask_detection(face)\n",
    "                \n",
    "                obj_byte = convert_nparr_to_byte(face)\n",
    "                extracted_face_list.append(\n",
    "                    (startX + x_origin, startY + y_origin, endX + x_origin, endY + y_origin\n",
    "                     , label, float(confidence), obj_byte))\n",
    "                \n",
    "        return extracted_face_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916a726",
   "metadata": {},
   "source": [
    "## 4. Detection\n",
    "Input:\n",
    "- **raw_img_content**: hình ảnh ở định dạng base64\n",
    "\n",
    "Output: \n",
    "- Danh sách các đối tượng phát hiện tương ứng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c00c4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(raw_img_content, id):\n",
    "    \"\"\"detection\n",
    "        input: raw_img_content (base64)\n",
    "        output: Danh sách các đối tượng phát hiện tương ứng \n",
    "            [(startX, startY, endX, endY, label, confidences, obj_byte)]\n",
    "    \"\"\"\n",
    "#     start ...\n",
    "    start = timer() \n",
    "    \n",
    "    image_input = convert_base64_to_nparr(raw_img_content)\n",
    "    \n",
    "    # Khai báo đối tượng Object Detector\n",
    "    obj_detector = Object_Detector(\n",
    "        weights_path = OBJECT_DETECTOR + \"/yolov3.weights\",\n",
    "        configuration_path = OBJECT_DETECTOR + \"/yolov3.cfg\",\n",
    "        labels = labels,\n",
    "    )\n",
    "    \n",
    "    # Khai báo đối tượng Face Mask Detector\n",
    "    face_mask_detector = Face_Mask_Detector(\n",
    "        prototxtPath = FACE_MASK_DETECTOR + \"/deploy.prototxt\",\n",
    "        weightsPath = FACE_MASK_DETECTOR + \"/res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "        mask_model_path = FACE_MASK_DETECTOR + \"/masknet_vgg19.h5\"\n",
    "    )\n",
    "    \n",
    "    # Model YOLOv3\n",
    "    extracted_object_list = obj_detector.solve(image_input)\n",
    "    \n",
    "    result = []\n",
    "    extracted_face_mask_list = []\n",
    "    for x in extracted_object_list:\n",
    "        result.append(x)\n",
    "        \n",
    "        # x = (startX, startY, endX, endY, label, confidences, obj_byte)\n",
    "        # Kiểm tra đối tượng detect được có phải là person hay không.\n",
    "        if x[4] == 'person':\n",
    "            person = convert_byte_to_nparr(x[6])\n",
    "            \n",
    "            # Model Face Mask\n",
    "            face_mask_list = face_mask_detector.solve(x[0], x[1], person)\n",
    "            for face_mask in face_mask_list:\n",
    "                extracted_face_mask_list.append(face_mask)\n",
    "\n",
    "    for x in extracted_face_mask_list:\n",
    "        result.append(x)\n",
    "        \n",
    "    # Lưu hình ảnh để hiện thị cho client\n",
    "    save_image(SERVING, 'input.png', image_input)\n",
    "\n",
    "    img_draw_box = image_input\n",
    "    for x in result:\n",
    "        startX, startY, endX, endY, label, confidence, obj_byte = x\n",
    "        \n",
    "        label = \"%s (%.3f)\" % (label, confidence)\n",
    "        \n",
    "        img_draw_box = draw_box(img_draw_box, startX, startY, endX, endY, label)\n",
    "    \n",
    "    # Lưu hình ảnh tương ứng với mỗi input\n",
    "    save_image(OUTPUT, 'images_{:05n}.png'.format(id), img_draw_box)\n",
    "    \n",
    "    # Lưu hình ảnh để hiện thị cho client\n",
    "    save_image(SERVING, 'output.png', img_draw_box)\n",
    "#     end ...\n",
    "    end = timer()\n",
    "    delta = end - start\n",
    "    print(('\\nDone ' + str(id) + ' after ' + str(delta) + ' seconds.\\n'))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a89b8fb",
   "metadata": {},
   "source": [
    "### 4.1 Định nghĩa schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351e7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_extraction_schema = ArrayType(StructType([\n",
    "    StructField(\"startX\", IntegerType(), False),\n",
    "    StructField(\"startY\", IntegerType(), False),\n",
    "    StructField(\"endX\", IntegerType(), False),\n",
    "    StructField(\"endY\", IntegerType(), False),\n",
    "    StructField(\"label\", StringType(), False),\n",
    "    StructField(\"confidence\", FloatType(), False),\n",
    "    StructField(\"img_content\", BinaryType(), False),\n",
    "]))\n",
    "\n",
    "Object_Extraction_UDF = f.udf(lambda Image, id: detection(Image, id),\n",
    "                            object_extraction_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879c827",
   "metadata": {},
   "source": [
    "## 5. Tiến hành Streaming dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e1e44",
   "metadata": {},
   "source": [
    "### 5.1 Streaming dữ liệu\n",
    "Dữ liệu sẽ được đọc stream từ file csv ở thư mục **./streaming/input** với schema tương ứng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9421e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = 'image STRING, timestamp STRING, src STRING, id INTEGER'\n",
    "df = spark.readStream.schema(sch).csv(INPUT).withColumn('timestamp', f.to_timestamp(\"timestamp\"))\n",
    "\n",
    "# df.select('timestamp', 'src', 'id').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919ccaaf",
   "metadata": {},
   "source": [
    "### Xử lý hình ảnh\n",
    "\n",
    "Tiến hành quá trình detect object thông qua hàm **Object_Extraction_UDF**.\n",
    "\n",
    "Dữ liệu sẽ được thêm vào cột **detected_object_list** có cấu trúc: **object_extraction_schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9eeb378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- src: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- detected_object_list: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- startX: integer (nullable = false)\n",
      " |    |    |-- startY: integer (nullable = false)\n",
      " |    |    |-- endX: integer (nullable = false)\n",
      " |    |    |-- endY: integer (nullable = false)\n",
      " |    |    |-- label: string (nullable = false)\n",
      " |    |    |-- confidence: float (nullable = false)\n",
      " |    |    |-- img_content: binary (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detected_object_list_df = df.withColumn(\"detected_object_list\",\n",
    "    Object_Extraction_UDF(\"image\", \"id\"))\n",
    "\n",
    "detected_object_list_df.printSchema()\n",
    "# detected_object_list_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "683a0af1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- src: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- extracted_object: struct (nullable = true)\n",
      " |    |-- startX: integer (nullable = false)\n",
      " |    |-- startY: integer (nullable = false)\n",
      " |    |-- endX: integer (nullable = false)\n",
      " |    |-- endY: integer (nullable = false)\n",
      " |    |-- label: string (nullable = false)\n",
      " |    |-- confidence: float (nullable = false)\n",
      " |    |-- img_content: binary (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detected_object_df = detected_object_list_df.withColumn(\"extracted_object\",\n",
    "  f.explode(f.col(\"detected_object_list\"))).drop(\"detected_object_list\")\n",
    "\n",
    "detected_object_df.printSchema()\n",
    "# detected_object_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37e21ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- src: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- startX: integer (nullable = true)\n",
      " |-- startY: integer (nullable = true)\n",
      " |-- endX: integer (nullable = true)\n",
      " |-- endY: integer (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- confidence: float (nullable = true)\n",
      " |-- img_content: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_detected_object_df = detected_object_df.select(f.col(\"image\"), f.col(\"timestamp\"), f.col(\"src\"), f.col(\"id\"),\n",
    "      f.col(\"extracted_object.startX\").alias(\"startX\"),\n",
    "    f.col(\"extracted_object.startY\").alias(\"startY\"),\n",
    "    f.col(\"extracted_object.endX\").alias(\"endX\"),\n",
    "    f.col(\"extracted_object.endY\").alias(\"endY\"),\n",
    "    f.col(\"extracted_object.label\").alias(\"label\"),\n",
    "    f.col(\"extracted_object.confidence\").alias(\"confidence\"),\n",
    "    f.col(\"extracted_object.img_content\").alias(\"img_content\"))\n",
    "\n",
    "flat_detected_object_df.printSchema()\n",
    "# flat_detected_object_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e566e",
   "metadata": {},
   "source": [
    "### Tổng kết lại quá trình xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a813d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- detection: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- count: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = flat_detected_object_df.groupBy('id').agg(f.collect_set('label').alias('detection')) \\\n",
    "    .withColumn('count', f.size('detection')) \\\n",
    "    .sort(\"id\", ascending=False)\n",
    "summary.printSchema()\n",
    "# summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94f481cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x1f5d107b850>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.writeStream.format('console') \\\n",
    "    .outputMode('complete') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
