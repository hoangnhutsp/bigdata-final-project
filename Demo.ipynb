{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89b6fd0",
   "metadata": {},
   "source": [
    "# DEMO: Đồ án cuối kỳ Big Data\n",
    "\n",
    "## Video Stream Analytics: Detect Object and Mask\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2fcfa",
   "metadata": {},
   "source": [
    "## 1. Khởi tạo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5b50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "\n",
    "# Xử lý ảnh\n",
    "import numpy as np\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "ORIGIN_PATH = \"D:/uit/IE212 - Bigdata/final-project\"\n",
    "\n",
    "INPUT = ORIGIN_PATH + \"/streaming/input\"\n",
    "OUTPUT = ORIGIN_PATH + \"/streaming/output\"\n",
    "\n",
    "OBJECT_DETECTOR = ORIGIN_PATH + \"/model/object-detector\"\n",
    "FACE_MASK_DETECTOR = ORIGIN_PATH + \"/model/face-mask-detector\"\n",
    "\n",
    "SERVING = ORIGIN_PATH + '/serving'\n",
    "\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"BIG DATA - Video Stream Analytics\") \\\n",
    "    .getOrCreate()\n",
    "def convert_byte_to_nparr(img_byte):\n",
    "    np_array = cv2.imdecode(np.asarray(bytearray(img_byte)), cv2.IMREAD_COLOR)\n",
    "    return np_array\n",
    "def convert_nparr_to_byte(img_np_array):\n",
    "    success, img = cv2.imencode('.png', img_np_array)\n",
    "    return img.tobytes()\n",
    "def convert_base64_to_nparr(raw_base64):\n",
    "    im_bytes = base64.b64decode(raw_base64)\n",
    "    im_arr = np.frombuffer(im_bytes, dtype=np.uint8)\n",
    "    return cv2.imdecode(im_arr, flags=cv2.IMREAD_COLOR)\n",
    "\n",
    "def save_image(path, file_name, image):\n",
    "    cv2.imwrite(path + \"/\" + file_name, image)\n",
    "    \n",
    "def correct_boxes(startX, startY, endX, endY, image_h, image_w, net_h, net_w):\n",
    "    startX = startX * net_h / image_h\n",
    "    startY = startY * net_h / image_h\n",
    "    endX = endX * net_w / image_w\n",
    "    endY = endY * net_w / image_w\n",
    "    return int(startX), int(startY), int(endX), int(endY)\n",
    "def draw_box(image, startX, startY, endX, endY, label):\n",
    "    if (label.startswith(\"with_mask\") or (label.startswith(\"without_mask\"))):\n",
    "        colors = (0,255,255)\n",
    "    else:\n",
    "        colors = (255, 0, 0)\n",
    "    \n",
    "    text_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1.3, 2)\n",
    "    text_w, text_h = text_size\n",
    "    cv2.rectangle(image, (startX, startY), (startX + text_w + 12, startY + text_h + 20), colors, -1)\n",
    "    cv2.rectangle(image, (startX, startY), (endX, endY), colors, 2)\n",
    "    cv2.putText(image, label, (startX + 8, startY + 34), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0,0,0), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219f9f4",
   "metadata": {},
   "source": [
    "## 2. Class Object Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222fd325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load danh sách label của mô hình YOLO từ file coco.names\n",
    "labels = open(OBJECT_DETECTOR + '/coco.names').read().strip().split('\\n')\n",
    "\n",
    "\n",
    "class Object_Detector():\n",
    "    \"\"\"Object Detector \n",
    "  \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 weights_path = 'yolov3.weights',\n",
    "                 configuration_path = 'file yolov3.cfg',\n",
    "                 labels = []):\n",
    "        \n",
    "        self.weights_path = weights_path\n",
    "        self.configuration_path = configuration_path\n",
    "        \n",
    "        self.probability_minimum = 0.5\n",
    "        self.threshold = 0.3\n",
    "        \n",
    "        self.labels = labels\n",
    "        \n",
    "        # Load mạng network của model YOLO\n",
    "        network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\n",
    "        layers_names_all = network.getLayerNames()\n",
    "        layers_names_output = [layers_names_all[i - 1] for i in network.getUnconnectedOutLayers()]\n",
    "        self.network = network\n",
    "        self.layers_names_output = layers_names_output\n",
    "        \n",
    "        # Non-Maximum Suppression (NMS) \n",
    "        self.NMSBoxes = cv2.dnn.NMSBoxes\n",
    "    def solve(self, image):\n",
    "        \"\"\"solve\n",
    "            input: image (numpy array)\n",
    "            output: Danh sách các đối tượng phát hiện tương ứng \n",
    "                [(startX, startY, endX, endY, label, confidences, obj_byte)]\n",
    "        \"\"\"\n",
    "        input_shape = image.shape\n",
    "        h, w = input_shape[:2]\n",
    "        \n",
    "        # Chuẩn hóa lại hình ảnh sử dụng model YOLO\n",
    "        blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    \n",
    "        self.network.setInput(blob)\n",
    "   \n",
    "        output_from_network = self.network.forward(self.layers_names_output)\n",
    "        \n",
    "        bounding_boxes = []\n",
    "        confidences = []\n",
    "        class_numbers = []\n",
    "    \n",
    "        for result in output_from_network:\n",
    "            for detection in result:\n",
    "                # Lấy danh sách các scores tương ứng với kết quả và tìm ra class với score lớn nhấn\n",
    "                scores = detection[5:]\n",
    "                class_current = np.argmax(scores)\n",
    "                confidence_current = scores[class_current]\n",
    "                \n",
    "                # probability_minimum: 0.5\n",
    "                if confidence_current > self.probability_minimum:\n",
    "                    # Tính toán các giá trị: x_min, y_min, box_width, box_height, confidences, class_numbers\n",
    "                    # chuẩn bị sử dụng Non-Maximum Suppression\n",
    "                    box_current = detection[0:4] * np.array([w, h, w, h])\n",
    "                    x_center, y_center, box_width, box_height = box_current.astype('int')\n",
    "                    x_min = int(x_center - (box_width / 2))\n",
    "                    y_min = int(y_center - (box_height / 2))\n",
    "                    bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "                    confidences.append(float(confidence_current))\n",
    "                    class_numbers.append(class_current)\n",
    "                    \n",
    "        # Kiểm tra nếu không tồn tại đối tượng trả về []\n",
    "        if len(bounding_boxes) == 0:\n",
    "            return []\n",
    "        # Tiến hành chuẩn hóa lại Boxes bằng cách sử dụng Non-Maximum Suppression\n",
    "        results = self.NMSBoxes(bounding_boxes, confidences, self.probability_minimum, self.threshold)\n",
    "        \n",
    "        obj_detection = []\n",
    "        for i in results.flatten():\n",
    "            # Đối với đối tượng phát hiện được ta tiến hành tính toán các giá trị:\n",
    "            # startX, startY, endX, endY, label, confidence, obj_byte\n",
    "            \n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "            startX = x_min\n",
    "            startY = y_min\n",
    "            endX = x_min + box_width\n",
    "            endY = y_min + box_height\n",
    "\n",
    "            (startX, startY) = (max(0, startX), max(0, startY))\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "            \n",
    "            \n",
    "            obj_detection.append((startX, startY, endX, endY, labels[int(class_numbers[i])], confidences[i]))\n",
    "        return obj_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc72b3",
   "metadata": {},
   "source": [
    "## 3. Class Face Mask Detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612f3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face_Mask_Detector():\n",
    "    \"\"\"Face Mask Detector\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 prototxtPath = \"deploy.prototxt\",\n",
    "                 weightsPath = \"res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "                 mask_model_path = \"masknet_vgg19.h5\"):\n",
    "\n",
    "        self.net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "        self.vgg19_model = load_model(mask_model_path)\n",
    "        self.probability_minimum = 0.5\n",
    "\n",
    "\n",
    "    def face_mask_detection(self, face):\n",
    "        \"\"\"face_mask_detection: Kiểm tra xem khuôn mặt có đeo khẩu trang hay không\n",
    "            input: face (numpy array)\n",
    "            output: with_mask hoặc without_mask và confidence tương tứng. \n",
    "        \"\"\"\n",
    "\n",
    "        face = cv2.resize(face, (128, 128))\n",
    "        face = face / 255.0\n",
    "\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "        \n",
    "        # model tính toán và trả về tỉ lệ tương ứng    \n",
    "        (mask, withoutMask) = self.vgg19_model.predict(face)[0]\n",
    "        \n",
    "        label = 'with_mask'\n",
    "        confidence = mask\n",
    "        if mask < withoutMask:\n",
    "            label = 'without_mask'\n",
    "            confidence = withoutMask\n",
    "            \n",
    "        return label, confidence\n",
    "    def solve(self, x_origin, y_origin, image):\n",
    "        \"\"\"solve\n",
    "            input: image (numpy array)\n",
    "            output: Danh sách các đối tượng phát hiện tương ứng \n",
    "                [(startX, startY, endX, endY, label, confidences, obj_byte)]\n",
    "        \"\"\"\n",
    "        (net_h, net_w) = image.shape[:2]\n",
    "        \n",
    "        (h, w) = image.shape[:2]\n",
    "        \n",
    "        # Chuẩn hóa lại hình ảnh sử dụng model Caffe\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        self.net.setInput(blob)\n",
    "        detections = self.net.forward()\n",
    "\n",
    "        extracted_face_list = []\n",
    "        \n",
    "        # Xử lý với từng khuôn mặt phát hiện\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            # probability_minimum: 0.5\n",
    "            if confidence > self.probability_minimum:\n",
    "                # Tính toán các giá trị: startX, startY, endX, endY, label, confidence, obj_byte\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                (startX, startY) = (max(0, startX), max(0, startY))\n",
    "                (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "                \n",
    "                \n",
    "                if startY >= endY or startX >= endX:\n",
    "                    continue\n",
    "#                 print(startY >= endY)\n",
    "                face = image[startY:endY, startX:endX]\n",
    "                \n",
    "                try:\n",
    "                    label, confidence = self.face_mask_detection(face)\n",
    "                except:\n",
    "                    label = 'unknown'\n",
    "                    confidence = 0\n",
    "                \n",
    "                extracted_face_list.append(\n",
    "                    (startX + x_origin, startY + y_origin, endX + x_origin, endY + y_origin\n",
    "                     , label, float(confidence)))\n",
    "                \n",
    "        return extracted_face_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916a726",
   "metadata": {},
   "source": [
    "## 4. Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c00c4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(raw_img_content, id):\n",
    "    \"\"\"detection\n",
    "        input: raw_img_content (base64)\n",
    "        output: Danh sách các đối tượng phát hiện tương ứng \n",
    "            [(startX, startY, endX, endY, label, confidences)]\n",
    "    \"\"\"\n",
    "#     start ...\n",
    "    start = timer() \n",
    "        \n",
    "    image_input = convert_base64_to_nparr(raw_img_content)\n",
    "    \n",
    "    # Khai báo đối tượng Object Detector\n",
    "    obj_detector = Object_Detector(\n",
    "        weights_path = OBJECT_DETECTOR + \"/yolov3.weights\",\n",
    "        configuration_path = OBJECT_DETECTOR + \"/yolov3.cfg\",\n",
    "        labels = labels,\n",
    "    )\n",
    "    \n",
    "    # Khai báo đối tượng Face Mask Detector\n",
    "    face_mask_detector = Face_Mask_Detector(\n",
    "        prototxtPath = FACE_MASK_DETECTOR + \"/deploy.prototxt\",\n",
    "        weightsPath = FACE_MASK_DETECTOR + \"/res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "        mask_model_path = FACE_MASK_DETECTOR + \"/masknet_vgg19.h5\"\n",
    "    )\n",
    "    \n",
    "    # Model YOLOv3\n",
    "    extracted_object_list = obj_detector.solve(image_input)\n",
    "    \n",
    "    result = []\n",
    "    extracted_face_mask_list = []\n",
    "    for x in extracted_object_list:\n",
    "        result.append(x)\n",
    "        \n",
    "        # x = (startX, startY, endX, endY, label, confidences, obj_byte)\n",
    "        startX, startY, endX, endY, label, confidence = x\n",
    "#         # Kiểm tra đối tượng detect được có phải là person hay không.\n",
    "        if label == 'person':\n",
    "            person = image_input[startY:endY, startX:endX]\n",
    "\n",
    "            # Model Face Mask\n",
    "            try:\n",
    "                extracted_face_mask_list = face_mask_detector.solve(startX, startY, person)\n",
    "            except:\n",
    "                extracted_face_mask_list = []\n",
    "\n",
    "    for x in extracted_face_mask_list:\n",
    "        result.append(x)\n",
    "        \n",
    "    save_image(SERVING, 'input.png', image_input)\n",
    "\n",
    "    img_draw_box = image_input\n",
    "    obj_detection = []\n",
    "    for x in result:\n",
    "        startX, startY, endX, endY, label, confidence = x\n",
    "        label = \"%s (%.3f)\" % (label, confidence)\n",
    "        obj_detection.append(label)\n",
    "        img_draw_box = draw_box(img_draw_box, startX, startY, endX, endY, label)\n",
    "\n",
    "    # Lưu hình ảnh tương ứng với mỗi input\n",
    "    save_image(OUTPUT, 'images_{:05n}.png'.format(id), img_draw_box)\n",
    "    \n",
    "    save_image(SERVING, 'output.png', img_draw_box)\n",
    "\n",
    "    end = timer()\n",
    "    delta = end - start\n",
    "    \n",
    "    return (delta, \",\".join(obj_detection))\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a89b8fb",
   "metadata": {},
   "source": [
    "### Định nghĩa schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351e7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_extraction_schema = StructType([\n",
    "    StructField(\"time_done\", FloatType(), False),\n",
    "    StructField(\"obj\", StringType(), False),\n",
    "])\n",
    "\n",
    "Object_Extraction_UDF = f.udf(lambda Image, id: detection(Image, id),\n",
    "                            object_extraction_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879c827",
   "metadata": {},
   "source": [
    "## 5. Tiến hành Streaming dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e1e44",
   "metadata": {},
   "source": [
    "### Streaming dữ liệu\n",
    "Dữ liệu sẽ được đọc stream từ file csv ở thư mục **./streaming/input** với schema tương ứng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9421e9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- src: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sch = 'image STRING, timestamp STRING, src STRING, id INTEGER'\n",
    "df = spark.readStream.schema(sch).csv(INPUT).withColumn('timestamp', f.to_timestamp(\"timestamp\"))\n",
    "\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919ccaaf",
   "metadata": {},
   "source": [
    "### Xử lý hình ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9eeb378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- src: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- detected_object_list: struct (nullable = true)\n",
      " |    |-- time_done: float (nullable = false)\n",
      " |    |-- obj: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detected_object_list_df = df.withColumn(\"detected_object_list\",\n",
    "    Object_Extraction_UDF(\"image\", \"id\"))\n",
    "\n",
    "detected_object_list_df.printSchema()\n",
    "# detected_object_list_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "705a2f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- time_done: float (nullable = true)\n",
      " |-- obj: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_detected_object_df = detected_object_list_df.select(f.col(\"id\"),\n",
    "    f.col(\"detected_object_list.time_done\").alias(\"time_done\"),\n",
    "    f.col(\"detected_object_list.obj\").alias(\"obj\"),\n",
    ")\n",
    "flat_detected_object_df.printSchema()\n",
    "# flat_detected_object_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ac1fb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x1c38f17b100>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_detected_object_df.writeStream.format('console') \\\n",
    "    .outputMode('append') \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
